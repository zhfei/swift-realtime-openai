import Core
import AVFAudio
import AVFoundation
import Foundation
@preconcurrency import LiveKitWebRTC
#if canImport(FoundationNetworking)
import FoundationNetworking
#endif

@Observable public final class WebRTCConnector: NSObject, Connector, Sendable {
	public enum WebRTCError: Error {
		case invalidEphemeralKey
		case missingAudioPermission
		case failedToCreateDataChannel
		case failedToCreatePeerConnection
		case badServerResponse(URLResponse)
		case failedToCreateSDPOffer(Swift.Error)
		case failedToSetLocalDescription(Swift.Error)
		case failedToSetRemoteDescription(Swift.Error)
		case failedToStartRecording(Swift.Error)
		case failedToStopRecording(Swift.Error)
		case failedToCreateAssetWriter(Swift.Error)
	}

	public let events: AsyncThrowingStream<ServerEvent, Error>
	@MainActor public private(set) var status = RealtimeAPI.Status.disconnected

	public var isMuted: Bool {
		!audioTrack.isEnabled
	}

	package let audioTrack: LKRTCAudioTrack
	private let dataChannel: LKRTCDataChannel
	private let connection: LKRTCPeerConnection

	private let stream: AsyncThrowingStream<ServerEvent, Error>.Continuation
	
	// å½•éŸ³ç›¸å…³å±æ€§
    nonisolated(unsafe) private var remoteAudioTrack: LKRTCAudioTrack?
    nonisolated(unsafe) private var audioEngine: AVAudioEngine?
    nonisolated(unsafe) private var remotePlayerNode: AVAudioPlayerNode?
    nonisolated(unsafe) private var fileHandle: FileHandle?
    nonisolated(unsafe) private var recordingURL: URL?
    nonisolated(unsafe) private var isRecording: Bool = false
    nonisolated(unsafe) private var wavDataSize: UInt32 = 0
    nonisolated(unsafe) private let recordingQueue = DispatchQueue(label: "com.realtime.recording", qos: .userInitiated)
	// æ—¶é—´æˆ³ç®¡ç†ï¼ˆç»Ÿä¸€ç®¡ç†ï¼Œç¡®ä¿ä¸¤è·¯éŸ³é¢‘æ—¶é—´æˆ³è¿ç»­ï¼‰
	nonisolated(unsafe) private var recordingStartTime: CMTime = .zero
	nonisolated(unsafe) private var lastPresentationTime: CMTime = .zero
	nonisolated(unsafe) private var totalFramesWritten: Int64 = 0
	// æ—¶é—´æˆ³é”ï¼Œç¡®ä¿çº¿ç¨‹å®‰å…¨
	private let timestampLock = NSLock()
	// ç»Ÿè®¡ä¿¡æ¯ï¼šè·³è¿‡çš„å¸§æ•°ï¼ˆå› ä¸ºæœªå‡†å¤‡å¥½ï¼‰
	nonisolated(unsafe) private var skippedFramesCount: Int64 = 0
	nonisolated(unsafe) private var skippedFramesCountLocal: Int64 = 0
	nonisolated(unsafe) private var skippedFramesCountRemote: Int64 = 0
	// éŸ³é¢‘å†™å…¥é˜Ÿåˆ—ï¼šç”¨äºä¸²è¡ŒåŒ–æœ¬åœ°å’Œè¿œç¨‹éŸ³é¢‘çš„å†™å…¥æ“ä½œ
	nonisolated(unsafe) private var audioWriteQueue: DispatchQueue?
	// éŸ³é¢‘ç¼“å†²åŒºé˜Ÿåˆ—ï¼šå­˜å‚¨å¾…å†™å…¥çš„éŸ³é¢‘æ ·æœ¬ï¼ˆæ”¹ä¸ºå­˜å‚¨ AVAudioPCMBufferï¼‰
	nonisolated(unsafe) private var audioBufferQueue: [(pcmBuffer: AVAudioPCMBuffer, source: String)] = []
	// ç¼“å†²åŒºé˜Ÿåˆ—é”
	private let bufferQueueLock = NSLock()
	// æ˜¯å¦æ­£åœ¨å¤„ç†å†™å…¥é˜Ÿåˆ—
	nonisolated(unsafe) private var isProcessingWriteQueue: Bool = false
	// è¯Šæ–­ç»Ÿè®¡ï¼šå›è°ƒæ¬¡æ•°
	nonisolated(unsafe) private var localAudioCallbackCount: Int64 = 0
	nonisolated(unsafe) private var remoteAudioCallbackCount: Int64 = 0
	// è¯Šæ–­ç»Ÿè®¡ï¼šå…¥é˜Ÿæ¬¡æ•°ï¼ˆæŒ‰æ¥æºï¼‰
	nonisolated(unsafe) private var enqueueCountLocal: Int64 = 0
	nonisolated(unsafe) private var enqueueCountRemote: Int64 = 0
	// è¯Šæ–­ç»Ÿè®¡ï¼šé˜Ÿåˆ—å¤„ç†æ¬¡æ•°
	nonisolated(unsafe) private var processQueueCount: Int64 = 0
    // è¯Šæ–­æ—¥å¿—ï¼šæ£€æŸ¥æ—¶é—´æˆ³è¿ç»­æ€§ï¼ˆæ¯100æ¬¡æ‰“å°ä¸€æ¬¡ï¼‰
    nonisolated(unsafe) var timestampCallCount: Int64 = 0
    nonisolated(unsafe) let timestampCallFlag: Int64 = 5000
	// è¯Šæ–­ç»Ÿè®¡ï¼šcreateSampleBuffer è°ƒç”¨æ¬¡æ•°ï¼ˆæŒ‰æ¥æºï¼‰
	nonisolated(unsafe) private var createSampleBufferCountLocal: Int64 = 0
	nonisolated(unsafe) private var createSampleBufferCountRemote: Int64 = 0
	// è¯Šæ–­ç»Ÿè®¡ï¼šä¸Šæ¬¡å›è°ƒæ—¶é—´ï¼ˆç”¨äºæ£€æµ‹å›è°ƒé—´éš”ï¼‰
	nonisolated(unsafe) private var lastLocalCallbackTime: Date?
	nonisolated(unsafe) private var lastRemoteCallbackTime: Date?
	// è¯Šæ–­å®šæ—¶å™¨
	nonisolated(unsafe) private var diagnosticTimer: DispatchSourceTimer?
	private static let factory: LKRTCPeerConnectionFactory = {
		LKRTCInitializeSSL()

		return LKRTCPeerConnectionFactory()
	}()

	private let encoder: JSONEncoder = {
		let encoder = JSONEncoder()
		encoder.keyEncodingStrategy = .convertToSnakeCase
		return encoder
	}()

	private let decoder: JSONDecoder = {
		let decoder = JSONDecoder()
		decoder.keyDecodingStrategy = .convertFromSnakeCase
		return decoder
	}()

	private init(connection: LKRTCPeerConnection, audioTrack: LKRTCAudioTrack, dataChannel: LKRTCDataChannel) {
		self.connection = connection
		self.audioTrack = audioTrack
		self.dataChannel = dataChannel
		(events, stream) = AsyncThrowingStream.makeStream(of: ServerEvent.self)

		super.init()

		connection.delegate = self as LKRTCPeerConnectionDelegate
		dataChannel.delegate = self as LKRTCDataChannelDelegate
	}

	deinit {
		disconnect()
	}

	package func connect(using request: URLRequest) async throws {
		guard connection.connectionState == .new else { return }

		guard AVAudioApplication.shared.recordPermission == .granted else {
			throw WebRTCError.missingAudioPermission
		}

		try await performHandshake(using: request)
		Self.configureAudioSession()
	}

	public func send(event: ClientEvent) throws {
		try dataChannel.sendData(LKRTCDataBuffer(data: encoder.encode(event), isBinary: false))
	}

	public func disconnect() {
		stopRecording()
		connection.close()
		stream.finish()
	}

	public func toggleMute() {
		audioTrack.isEnabled.toggle()
	}
}

extension WebRTCConnector {
	public static func create(connectingTo request: URLRequest) async throws -> WebRTCConnector {
		let connector = try create()
		try await connector.connect(using: request)
		return connector
	}

	package static func create() throws -> WebRTCConnector {
		guard let connection = factory.peerConnection(
			with: LKRTCConfiguration(),
			constraints: LKRTCMediaConstraints(mandatoryConstraints: nil, optionalConstraints: nil),
			delegate: nil
		) else { throw WebRTCError.failedToCreatePeerConnection }

		let audioTrack = Self.setupLocalAudio(for: connection)

		guard let dataChannel = connection.dataChannel(forLabel: "oai-events", configuration: LKRTCDataChannelConfiguration()) else {
			throw WebRTCError.failedToCreateDataChannel
		}

		return self.init(connection: connection, audioTrack: audioTrack, dataChannel: dataChannel)
	}
}

private extension WebRTCConnector {
	static func setupLocalAudio(for connection: LKRTCPeerConnection) -> LKRTCAudioTrack {
		let audioSource = factory.audioSource(with: LKRTCMediaConstraints(
			mandatoryConstraints: [
				"googNoiseSuppression": "true", "googHighpassFilter": "true",
				"googEchoCancellation": "true", "googAutoGainControl": "true",
			],
			optionalConstraints: nil
		))

		return tap(factory.audioTrack(with: audioSource, trackId: "local_audio")) { audioTrack in
			connection.add(audioTrack, streamIds: ["local_stream"])
		}
	}

	static func configureAudioSession() {
		#if !os(macOS)
		do {
			let audioSession = AVAudioSession.sharedInstance()
			#if os(tvOS)
			try audioSession.setCategory(.playAndRecord, options: [])
			#else
			try audioSession.setCategory(.playAndRecord, options: [.defaultToSpeaker])
			#endif
			try audioSession.setMode(.videoChat)
			try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
		} catch {
			print("Failed to configure AVAudioSession: \(error)")
		}
		#endif
	}

	func performHandshake(using request: URLRequest) async throws {
		let sdp = try await Result { try await connection.offer(for: LKRTCMediaConstraints(mandatoryConstraints: ["levelControl": "true"], optionalConstraints: nil)) }
			.mapError(WebRTCError.failedToCreateSDPOffer)
			.get()

		do { try await connection.setLocalDescription(sdp) }
		catch { throw WebRTCError.failedToSetLocalDescription(error) }

		let remoteSdp = try await fetchRemoteSDP(using: request, localSdp: connection.localDescription!.sdp)

		do { try await connection.setRemoteDescription(LKRTCSessionDescription(type: .answer, sdp: remoteSdp)) }
		catch { throw WebRTCError.failedToSetRemoteDescription(error) }
	}

	private func fetchRemoteSDP(using request: URLRequest, localSdp: String) async throws -> String {
		var request = request
		request.httpBody = localSdp.data(using: .utf8)
		request.setValue("application/sdp", forHTTPHeaderField: "Content-Type")

		let (data, response) = try await URLSession.shared.data(for: request)

		guard let response = response as? HTTPURLResponse, response.statusCode == 201, let remoteSdp = String(data: data, encoding: .utf8) else {
			if (response as? HTTPURLResponse)?.statusCode == 401 { throw WebRTCError.invalidEphemeralKey }
			throw WebRTCError.badServerResponse(response)
		}

		return remoteSdp
	}
	
	// MARK: - å½•éŸ³åŠŸèƒ½
	
	/// å¼€å§‹å½•åˆ¶ç”µè¯å¯¹è¯
	func startRecording() async throws {
		guard !isRecording else { return }
		
		try await withCheckedThrowingContinuation { (continuation: CheckedContinuation<Void, Error>) in
			recordingQueue.async { [weak self] in
				guard let self = self else {
					continuation.resume(throwing: WebRTCError.failedToStartRecording(NSError(domain: "WebRTC", code: -1, userInfo: [NSLocalizedDescriptionKey: "Self is nil"])))
					return
				}
				
				do {
					print("========================================")
					print("[WebRTCConnector] ğŸ™ï¸ å¼€å§‹å½•åˆ¶æµç¨‹")
					print("========================================")
					
					// åˆ›å»ºå½•åˆ¶æ–‡ä»¶URL
					let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
					let fileName = "recording_\(Date().timeIntervalSince1970).wav"
					let fileURL = documentsPath.appendingPathComponent(fileName)
					print("[WebRTCConnector] ğŸ“ æ–‡ä»¶è·¯å¾„: \(fileURL.path)")
					
					// å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ é™¤å®ƒ
					if FileManager.default.fileExists(atPath: fileURL.path) {
						try? FileManager.default.removeItem(at: fileURL)
						print("[WebRTCConnector] âš ï¸ å·²åˆ é™¤å·²å­˜åœ¨çš„æ–‡ä»¶")
					}
					
					self.recordingURL = fileURL
					
					// åˆ›å»º WAV æ–‡ä»¶å¹¶å†™å…¥æ–‡ä»¶å¤´
					try self.writeWAVHeader(to: fileURL, sampleRate: 24000, channels: 1, bitsPerSample: 16, dataSize: 0)
					
					// æ‰“å¼€æ–‡ä»¶å¥æŸ„ç”¨äºè¿½åŠ å†™å…¥ PCM æ•°æ®
					guard let fileHandle = try? FileHandle(forWritingTo: fileURL) else {
						throw WebRTCError.failedToStartRecording(NSError(domain: "WebRTC", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ— æ³•æ‰“å¼€æ–‡ä»¶å¥æŸ„"]))
					}
					
					// ç§»åŠ¨åˆ°æ–‡ä»¶æœ«å°¾ï¼ˆæ–‡ä»¶å¤´ä¹‹åï¼‰
					fileHandle.seekToEndOfFile()
					self.fileHandle = fileHandle
					
					print("[WebRTCConnector] ğŸµ WAV éŸ³é¢‘è®¾ç½®:")
					print("  - æ ¼å¼: WAV (PCM)")
					print("  - é‡‡æ ·ç‡: 24000 Hz")
					print("  - å£°é“æ•°: 1 (å•å£°é“)")
					print("  - ä½æ·±åº¦: 16 ä½")
					print("  - PCMæ ¼å¼: Int16, å°ç«¯åº")
				
				self.wavDataSize = 0
				// åˆå§‹åŒ–æ—¶é—´æˆ³
				self.recordingStartTime = .zero
				self.lastPresentationTime = .zero
				self.totalFramesWritten = 0
				// åˆå§‹åŒ–ç»Ÿè®¡è®¡æ•°å™¨
				self.skippedFramesCount = 0
				self.skippedFramesCountLocal = 0
				self.skippedFramesCountRemote = 0
				// åˆ›å»ºéŸ³é¢‘å†™å…¥é˜Ÿåˆ—ï¼ˆä¸²è¡Œé˜Ÿåˆ—ï¼Œç¡®ä¿æŒ‰é¡ºåºå†™å…¥ï¼‰
				self.audioWriteQueue = DispatchQueue(label: "com.realtime.audioWrite", qos: .userInitiated)
				self.audioBufferQueue = []
				self.isProcessingWriteQueue = false
				print("[WebRTCConnector] âœ… æ—¶é—´æˆ³ç®¡ç†å™¨å’Œç»Ÿè®¡è®¡æ•°å™¨å·²åˆå§‹åŒ–")
				print("[WebRTCConnector] âœ… éŸ³é¢‘å†™å…¥é˜Ÿåˆ—å·²åˆ›å»º")
				print("[WebRTCConnector] âœ… WAV æ–‡ä»¶å·²åˆ›å»ºï¼Œæ–‡ä»¶å¥æŸ„å·²æ‰“å¼€")
				
				// é…ç½® AVAudioSession æ”¯æŒåŒæ—¶æ’­æ”¾å’Œå½•åˆ¶
				let audioSession = AVAudioSession.sharedInstance()
				do {
					try audioSession.setCategory(.playAndRecord, mode: .default, options: [.allowBluetooth, .defaultToSpeaker, .mixWithOthers])
					try audioSession.setActive(true)
					print("[WebRTCConnector] âœ… AVAudioSession å·²é…ç½®ä¸º playAndRecord æ¨¡å¼")
				} catch {
					print("[WebRTCConnector] âš ï¸ AVAudioSession é…ç½®å¤±è´¥: \(error.localizedDescription)")
				}
				
				// åˆ›å»º AVAudioEngine ç”¨äºæ··åˆéŸ³é¢‘
				let engine = AVAudioEngine()
				print("[WebRTCConnector] âœ… AVAudioEngine åˆ›å»ºæˆåŠŸ")
				
				// è·å– inputNode çš„ç¡¬ä»¶æ ¼å¼ï¼ˆå¿…é¡»ä½¿ç”¨ç¡¬ä»¶é‡‡æ ·ç‡ï¼Œå¦åˆ™ä¼šå´©æºƒï¼‰
				let inputFormat = engine.inputNode.inputFormat(forBus: 0)
				print("[WebRTCConnector] ğŸ“Š è¾“å…¥èŠ‚ç‚¹ç¡¬ä»¶æ ¼å¼:")
				print("  - é‡‡æ ·ç‡: \(inputFormat.sampleRate) Hz")
				print("  - å£°é“æ•°: \(inputFormat.channelCount)")
				print("  - æ ¼å¼: \(inputFormat.commonFormat.rawValue)")
				print("  - æ˜¯å¦äº¤é”™: \(inputFormat.isInterleaved)")
				
				guard inputFormat.sampleRate > 0 else {
					print("[WebRTCConnector] âŒ è¾“å…¥èŠ‚ç‚¹é‡‡æ ·ç‡æ— æ•ˆ: \(inputFormat.sampleRate)")
					throw WebRTCError.failedToStartRecording(NSError(domain: "WebRTC", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ— æ³•è·å–è¾“å…¥èŠ‚ç‚¹æ ¼å¼"]))
				}
				
				// åˆ›å»ºæ ¼å¼è½¬æ¢å™¨ï¼Œå°†ç¡¬ä»¶æ ¼å¼è½¬æ¢ä¸ºç›®æ ‡æ ¼å¼ï¼ˆ24000 Hzï¼‰
				guard let converterFormat = AVAudioFormat(commonFormat: .pcmFormatFloat32, sampleRate: 24000, channels: 1, interleaved: false) else {
					print("[WebRTCConnector] âŒ æ— æ³•åˆ›å»ºè½¬æ¢æ ¼å¼")
					throw WebRTCError.failedToStartRecording(NSError(domain: "WebRTC", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ— æ³•åˆ›å»ºè½¬æ¢æ ¼å¼"]))
				}
				print("[WebRTCConnector] âœ… è½¬æ¢ç›®æ ‡æ ¼å¼åˆ›å»ºæˆåŠŸ:")
				print("  - é‡‡æ ·ç‡: \(converterFormat.sampleRate) Hz")
				print("  - å£°é“æ•°: \(converterFormat.channelCount)")
				
				// åˆ›å»ºæ ¼å¼è½¬æ¢å™¨ï¼ˆåœ¨é—­åŒ…å†…åˆ›å»ºï¼Œé¿å…æ•è·é—®é¢˜ï¼‰
				guard let converter = AVAudioConverter(from: inputFormat, to: converterFormat) else {
					print("[WebRTCConnector] âŒ æ— æ³•åˆ›å»ºéŸ³é¢‘è½¬æ¢å™¨")
					print("  - æºæ ¼å¼: \(inputFormat.sampleRate)Hz, \(inputFormat.channelCount)ch")
					print("  - ç›®æ ‡æ ¼å¼: \(converterFormat.sampleRate)Hz, \(converterFormat.channelCount)ch")
					throw WebRTCError.failedToStartRecording(NSError(domain: "WebRTC", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ— æ³•åˆ›å»ºéŸ³é¢‘è½¬æ¢å™¨"]))
				}
				print("[WebRTCConnector] âœ… æœ¬åœ°éŸ³é¢‘è½¬æ¢å™¨åˆ›å»ºæˆåŠŸ")
				
				// åˆ›å»ºè¿œç¨‹éŸ³é¢‘æ’­æ”¾èŠ‚ç‚¹ï¼ˆç”¨äºæ¥æ”¶è¿œç¨‹éŸ³é¢‘ï¼‰
				let remotePlayerNode = AVAudioPlayerNode()
				engine.attach(remotePlayerNode)
				self.remotePlayerNode = remotePlayerNode
				print("[WebRTCConnector] âœ… è¿œç¨‹éŸ³é¢‘æ’­æ”¾èŠ‚ç‚¹å·²åˆ›å»ºå¹¶é™„åŠ åˆ°å¼•æ“")
				
				// åˆ›å»ºæœ€ç»ˆæ··åˆå™¨èŠ‚ç‚¹ï¼Œç”¨äºæ··åˆæœ¬åœ°å’Œè¿œç¨‹éŸ³é¢‘
				let finalMixerNode = AVAudioMixerNode()
				engine.attach(finalMixerNode)
				
				// è¿æ¥æœ¬åœ°éŸ³é¢‘ï¼ˆinputNodeï¼‰åˆ°æœ€ç»ˆæ··åˆå™¨ - ä½¿ç”¨ç¡¬ä»¶æ ¼å¼
				engine.connect(engine.inputNode, to: finalMixerNode, format: inputFormat)
				print("[WebRTCConnector] âœ… æœ¬åœ°éŸ³é¢‘å·²è¿æ¥åˆ°æœ€ç»ˆæ··åˆå™¨")
				
				// è·å–è¿œç¨‹éŸ³é¢‘æ ¼å¼ï¼ˆä½¿ç”¨ä¸æœ¬åœ°éŸ³é¢‘ç›¸åŒçš„æ ¼å¼ï¼Œç¨åä¼šåœ¨ connectRemoteAudioToEngine ä¸­è°ƒæ•´ï¼‰
				// å…ˆä½¿ç”¨ä¸€ä¸ªé»˜è®¤æ ¼å¼ï¼Œå®é™…æ ¼å¼å°†åœ¨è¿æ¥è¿œç¨‹éŸ³é¢‘æ—¶ç¡®å®š
				let remoteFormat = AVAudioFormat(commonFormat: .pcmFormatFloat32, sampleRate: 48000, channels: 1, interleaved: false) ?? inputFormat
				
				// è¿æ¥è¿œç¨‹éŸ³é¢‘æ’­æ”¾èŠ‚ç‚¹åˆ°æœ€ç»ˆæ··åˆå™¨
				engine.connect(remotePlayerNode, to: finalMixerNode, format: remoteFormat)
				print("[WebRTCConnector] âœ… è¿œç¨‹éŸ³é¢‘æ’­æ”¾èŠ‚ç‚¹å·²è¿æ¥åˆ°æœ€ç»ˆæ··åˆå™¨")
				
				// è·å– mainMixerNode çš„è¾“å‡ºæ ¼å¼ï¼ˆç”¨äºæœ€ç»ˆè¾“å‡ºï¼‰
				let outputFormat = engine.mainMixerNode.outputFormat(forBus: 0)
				print("[WebRTCConnector] ğŸ“Š è¾“å‡ºèŠ‚ç‚¹æ ¼å¼:")
				print("  - é‡‡æ ·ç‡: \(outputFormat.sampleRate) Hz")
				print("  - å£°é“æ•°: \(outputFormat.channelCount)")
				
				// å°†æœ€ç»ˆæ··åˆå™¨è¿æ¥åˆ°è¾“å‡ºèŠ‚ç‚¹ï¼ˆç”¨äºæ’­æ”¾ï¼‰
				engine.connect(finalMixerNode, to: engine.outputNode, format: outputFormat)
				print("[WebRTCConnector] âœ… æœ€ç»ˆæ··åˆå™¨å·²è¿æ¥åˆ°è¾“å‡ºèŠ‚ç‚¹")
				
				// æ³¨æ„ï¼šWebRTC çš„è¿œç¨‹éŸ³é¢‘è½¨é“é€šè¿‡ç³»ç»ŸéŸ³é¢‘è¾“å‡ºè‡ªåŠ¨æ’­æ”¾
				// ç”±äº LiveKitWebRTC å¯èƒ½ä¸ç›´æ¥æä¾›éŸ³é¢‘æ•°æ®æµ APIï¼Œè¿œç¨‹éŸ³é¢‘å¯èƒ½ä¸ä¼šè¿›å…¥æˆ‘ä»¬çš„ AVAudioEngine
				// æˆ‘ä»¬å·²ç»åœ¨ finalMixerNode ä¸Šå®‰è£…äº† tap æ¥æ•è·æ··åˆåçš„éŸ³é¢‘
				// å¦‚æœè¿œç¨‹éŸ³é¢‘æ²¡æœ‰è¿›å…¥å¼•æ“ï¼Œæ··åˆéŸ³é¢‘å°†åªåŒ…å«æœ¬åœ°éŸ³é¢‘
				// è¿™éœ€è¦åœ¨ connectRemoteAudioToEngine() ä¸­è¿›ä¸€æ­¥å¤„ç†
				
				// åˆ›å»ºæ··åˆéŸ³é¢‘è½¬æ¢å™¨ï¼ˆä» outputFormat è½¬æ¢åˆ°ç›®æ ‡æ ¼å¼ï¼‰
				guard let mixedConverter = AVAudioConverter(from: outputFormat, to: converterFormat) else {
					print("[WebRTCConnector] âŒ æ— æ³•åˆ›å»ºæ··åˆéŸ³é¢‘è½¬æ¢å™¨")
					print("  - æºæ ¼å¼: \(outputFormat.sampleRate)Hz, \(outputFormat.channelCount)ch")
					print("  - ç›®æ ‡æ ¼å¼: \(converterFormat.sampleRate)Hz, \(converterFormat.channelCount)ch")
					throw WebRTCError.failedToStartRecording(NSError(domain: "WebRTC", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ— æ³•åˆ›å»ºæ··åˆéŸ³é¢‘è½¬æ¢å™¨"]))
				}
				print("[WebRTCConnector] âœ… æ··åˆéŸ³é¢‘è½¬æ¢å™¨åˆ›å»ºæˆåŠŸ")
				
				// ä»æœ€ç»ˆæ··åˆå™¨èŠ‚ç‚¹å®‰è£… tapï¼Œæ•è·æ··åˆåçš„éŸ³é¢‘
				// ä½¿ç”¨ç¡¬ä»¶æ ¼å¼æ•è·ï¼Œç„¶ååœ¨å›è°ƒä¸­è½¬æ¢ä¸ºç›®æ ‡æ ¼å¼
				// é‡ç½®ç»Ÿè®¡è®¡æ•°å™¨
				self.localAudioCallbackCount = 0
				self.lastLocalCallbackTime = Date()
				finalMixerNode.installTap(onBus: 0, bufferSize: 4096, format: outputFormat) { [weak self, mixedConverter, converterFormat] buffer, time in
					guard let self = self, self.isRecording else {
						return
					}
					
					// è¿™æ˜¯æ··åˆåçš„éŸ³é¢‘ï¼ˆåŒ…å«æœ¬åœ°å’Œè¿œç¨‹ï¼‰
					self.localAudioCallbackCount += 1
					let now = Date()
					let timeSinceLastCallback: TimeInterval
					if let lastTime = self.lastLocalCallbackTime {
						timeSinceLastCallback = now.timeIntervalSince(lastTime)
					} else {
						timeSinceLastCallback = 0
					}
					self.lastLocalCallbackTime = now
					
					// è¯Šæ–­æ—¥å¿—ï¼šè®°å½•å›è°ƒè§¦å‘ï¼ˆå‰100æ¬¡æ¯æ¬¡éƒ½è®°å½•ï¼Œä¹‹åæ¯100æ¬¡æ‰“å°ä¸€æ¬¡ï¼‰
					if self.localAudioCallbackCount <= 100 || self.localAudioCallbackCount % 100 == 0 {
						print("[WebRTCConnector] ğŸ” [æ··åˆéŸ³é¢‘] Tap å›è°ƒè§¦å‘ #\(self.localAudioCallbackCount) - å¸§æ•°: \(buffer.frameLength), é‡‡æ ·ç‡: \(buffer.format.sampleRate)Hz, è·ä¸Šæ¬¡å›è°ƒ: \(String(format: "%.3f", timeSinceLastCallback))ç§’")
					}
					
					// å¦‚æœå›è°ƒé—´éš”è¿‡é•¿ï¼ˆè¶…è¿‡0.5ç§’ï¼‰ï¼Œæ‰“å°è­¦å‘Š
					if timeSinceLastCallback > 0.5 && self.localAudioCallbackCount > 1 {
						print("[WebRTCConnector] âš ï¸ [æ··åˆéŸ³é¢‘] Tap å›è°ƒé—´éš”è¿‡é•¿: \(String(format: "%.3f", timeSinceLastCallback))ç§’ (å›è°ƒ#\(self.localAudioCallbackCount))")
					}
					
					// è®°å½•åŸå§‹ buffer ä¿¡æ¯
					let originalFrames = buffer.frameLength
					let originalSampleRate = buffer.format.sampleRate
					
					// è½¬æ¢éŸ³é¢‘æ ¼å¼åˆ°ç›®æ ‡æ ¼å¼ï¼ˆ24000 Hzï¼‰
					guard let convertedBuffer = AVAudioPCMBuffer(pcmFormat: converterFormat, frameCapacity: buffer.frameLength) else {
						print("[WebRTCConnector] âŒ æ··åˆéŸ³é¢‘: æ— æ³•åˆ›å»ºè½¬æ¢ buffer (å®¹é‡: \(buffer.frameLength))")
						return
					}
					
					var error: NSError?
					let inputBlock: AVAudioConverterInputBlock = { _, outStatus in
						outStatus.pointee = .haveData
						return buffer
					}
					
					mixedConverter.convert(to: convertedBuffer, error: &error, withInputFrom: inputBlock)
					
					if error == nil {
						// ç¡®ä¿ frameLength æ­£ç¡®è®¾ç½®
						if convertedBuffer.frameLength == 0 {
							convertedBuffer.frameLength = convertedBuffer.frameCapacity
							print("[WebRTCConnector] âš ï¸ æ··åˆéŸ³é¢‘: frameLength ä¸º 0ï¼Œå·²è®¾ç½®ä¸º frameCapacity (\(convertedBuffer.frameCapacity))")
						}
						
						// åˆ†æéŸ³é¢‘æ•°æ®ï¼ˆå‰10æ¬¡æˆ–æ¯100æ¬¡ï¼‰
						let shouldAnalyze = self.localAudioCallbackCount <= 10 || self.localAudioCallbackCount % 100 == 0
						if shouldAnalyze {
							let (maxVal, minVal, rms, isSilent) = self.analyzeAudioBuffer(convertedBuffer)
							print("[WebRTCConnector] ğŸ“Š [æ··åˆéŸ³é¢‘] éŸ³é¢‘æ•°æ®åˆ†æ #\(self.localAudioCallbackCount):")
							print("  - æœ€å¤§å€¼: \(String(format: "%.6f", maxVal))")
							print("  - æœ€å°å€¼: \(String(format: "%.6f", minVal))")
							print("  - RMSå€¼: \(String(format: "%.6f", rms))")
							print("  - æ˜¯å¦é™éŸ³: \(isSilent ? "æ˜¯ âš ï¸" : "å¦ âœ…")")
							if isSilent {
								print("[WebRTCConnector] âš ï¸ [æ··åˆéŸ³é¢‘] æ£€æµ‹åˆ°é™éŸ³æ•°æ® - å›è°ƒ#\(self.localAudioCallbackCount)")
							}
						}
						
						// è¯Šæ–­æ—¥å¿—ï¼šè®°å½•å‡†å¤‡å…¥é˜Ÿï¼ˆå‰10æ¬¡è¯¦ç»†è®°å½•ï¼‰
						if self.localAudioCallbackCount <= 10 {
							print("[WebRTCConnector] ğŸ” [æ··åˆéŸ³é¢‘] å‡†å¤‡å…¥é˜Ÿ - è½¬æ¢åå¸§æ•°: \(convertedBuffer.frameLength), é‡‡æ ·ç‡: \(convertedBuffer.format.sampleRate)Hz")
						}
						
						// å°†è½¬æ¢åçš„æ··åˆéŸ³é¢‘ buffer å…¥é˜Ÿï¼ˆsource æ ‡è®°ä¸º"æ··åˆ"ï¼‰
						self.enqueueAudioPCMBuffer(convertedBuffer, source: "æ··åˆ")
						
						// è¯Šæ–­æ—¥å¿—ï¼šè®°å½•å…¥é˜ŸæˆåŠŸï¼ˆå‰10æ¬¡è¯¦ç»†è®°å½•ï¼‰
						if self.localAudioCallbackCount <= 10 {
							print("[WebRTCConnector] âœ… [æ··åˆéŸ³é¢‘] å·²å…¥é˜Ÿ - å›è°ƒ#\(self.localAudioCallbackCount)")
						}
					} else {
						print("[WebRTCConnector] âŒ æ··åˆéŸ³é¢‘æ ¼å¼è½¬æ¢å¤±è´¥:")
						print("  - é”™è¯¯: \(error?.localizedDescription ?? "æœªçŸ¥é”™è¯¯")")
						print("  - åŸå§‹å¸§æ•°: \(originalFrames), é‡‡æ ·ç‡: \(originalSampleRate)Hz")
					}
				}
				print("[WebRTCConnector] âœ… æ··åˆéŸ³é¢‘ tap å·²å®‰è£… (bufferSize: 4096)")
					
				// å¯åŠ¨éŸ³é¢‘å¼•æ“
				try engine.start()
				self.audioEngine = engine
				self.isRecording = true
				
				print("[WebRTCConnector] âœ… éŸ³é¢‘å¼•æ“å·²å¯åŠ¨")
				print("[WebRTCConnector] âœ… å½•åˆ¶å·²å¼€å§‹ï¼Œæ–‡ä»¶ä¿å­˜è‡³: \(fileURL.path)")
				
				// è¯Šæ–­ï¼šæ£€æŸ¥è¿œç¨‹éŸ³é¢‘è½¨é“çŠ¶æ€
				if let remoteTrack = self.remoteAudioTrack {
					print("[WebRTCConnector] ğŸ” [å½•åˆ¶å¼€å§‹] è¿œç¨‹éŸ³é¢‘è½¨é“çŠ¶æ€:")
					print("  - è½¨é“ID: \(remoteTrack.trackId)")
					print("  - æ˜¯å¦å¯ç”¨: \(remoteTrack.isEnabled)")
					print("  - çŠ¶æ€: \(remoteTrack.readyState.rawValue)")
					print("  - æ³¨æ„ï¼šè¿œç¨‹éŸ³é¢‘åº”é€šè¿‡ mainMixerNode çš„ tap æ•è·")
					
					// è¿æ¥è¿œç¨‹éŸ³é¢‘è½¨é“åˆ°éŸ³é¢‘å¼•æ“
					self.connectRemoteAudioToEngine()
				} else {
					print("[WebRTCConnector] âš ï¸ [å½•åˆ¶å¼€å§‹] è¿œç¨‹éŸ³é¢‘è½¨é“å°šæœªè·å–")
				}
				
				// è¯Šæ–­ï¼šæ£€æŸ¥éŸ³é¢‘å¼•æ“èŠ‚ç‚¹è¿æ¥çŠ¶æ€
				print("[WebRTCConnector] ğŸ” [å½•åˆ¶å¼€å§‹] éŸ³é¢‘å¼•æ“èŠ‚ç‚¹çŠ¶æ€:")
				print("  - è¾“å…¥èŠ‚ç‚¹å·²è¿æ¥: \(engine.inputNode.outputFormat(forBus: 0).sampleRate > 0)")
				print("  - mainMixerNode å·²è¿æ¥: \(engine.mainMixerNode.outputFormat(forBus: 0).sampleRate > 0)")
				print("  - è¾“å‡ºèŠ‚ç‚¹å·²è¿æ¥: \(engine.outputNode.inputFormat(forBus: 0).sampleRate > 0)")
				print("  - å·²é™„åŠ èŠ‚ç‚¹æ•°: \(engine.attachedNodes.count)")
				
				// è¯Šæ–­ï¼šæ£€æŸ¥ finalMixerNode çš„è¾“å…¥è¿æ¥
				if let finalMixerNode = engine.attachedNodes.first(where: { $0 is AVAudioMixerNode && $0 !== engine.mainMixerNode }) as? AVAudioMixerNode {
					let inputFormat = finalMixerNode.inputFormat(forBus: 0)
					print("[WebRTCConnector] ğŸ” [å½•åˆ¶å¼€å§‹] finalMixerNode è¾“å…¥è¿æ¥çŠ¶æ€:")
					print("  - Bus 0 (æœ¬åœ°éŸ³é¢‘) é‡‡æ ·ç‡: \(inputFormat.sampleRate) Hz")
					if finalMixerNode.numberOfInputs > 1 {
						let remoteInputFormat = finalMixerNode.inputFormat(forBus: 1)
						print("  - Bus 1 (è¿œç¨‹éŸ³é¢‘) é‡‡æ ·ç‡: \(remoteInputFormat.sampleRate) Hz")
					} else {
						print("  - Bus 1 (è¿œç¨‹éŸ³é¢‘): æœªè¿æ¥")
					}
				}
				
				// å¯åŠ¨å®šæœŸè¯Šæ–­æ£€æŸ¥ï¼ˆæ¯5ç§’æ‰“å°ä¸€æ¬¡ç»Ÿè®¡ä¿¡æ¯ï¼‰
				let timer = DispatchSource.makeTimerSource(queue: self.recordingQueue)
				timer.schedule(deadline: .now() + 5.0, repeating: 5.0)
				timer.setEventHandler { [weak self] in
					guard let self = self, self.isRecording else {
						timer.cancel()
						return
					}
					
					let now = Date()
					let timeSinceLastLocal: TimeInterval
					let timeSinceLastRemote: TimeInterval
					
					if let lastLocal = self.lastLocalCallbackTime {
						timeSinceLastLocal = now.timeIntervalSince(lastLocal)
					} else {
						timeSinceLastLocal = -1
					}
					
					if let lastRemote = self.lastRemoteCallbackTime {
						timeSinceLastRemote = now.timeIntervalSince(lastRemote)
					} else {
						timeSinceLastRemote = -1
					}
					
					print("[WebRTCConnector] ğŸ“Š [å®šæœŸè¯Šæ–­] Tap å›è°ƒç»Ÿè®¡:")
					print("  - æœ¬åœ°éŸ³é¢‘å›è°ƒæ¬¡æ•°: \(self.localAudioCallbackCount), è·ä¸Šæ¬¡å›è°ƒ: \(timeSinceLastLocal >= 0 ? String(format: "%.3f", timeSinceLastLocal) : "ä»æœª")ç§’")
					print("  - è¿œç¨‹éŸ³é¢‘å›è°ƒæ¬¡æ•°: \(self.remoteAudioCallbackCount), è·ä¸Šæ¬¡å›è°ƒ: \(timeSinceLastRemote >= 0 ? String(format: "%.3f", timeSinceLastRemote) : "ä»æœª")ç§’")
					print("  - æœ¬åœ° createSampleBuffer æ¬¡æ•°: \(self.createSampleBufferCountLocal)")
					print("  - è¿œç¨‹ createSampleBuffer æ¬¡æ•°: \(self.createSampleBufferCountRemote)")
					print("  - æœ¬åœ°å…¥é˜Ÿæ¬¡æ•°: \(self.enqueueCountLocal), è¿œç¨‹å…¥é˜Ÿæ¬¡æ•°: \(self.enqueueCountRemote)")
					
					// å¦‚æœå›è°ƒåœæ­¢ï¼ˆè¶…è¿‡2ç§’æ²¡æœ‰å›è°ƒï¼‰ï¼Œæ‰“å°è­¦å‘Š
					if timeSinceLastLocal > 2.0 && self.localAudioCallbackCount > 0 {
						print("[WebRTCConnector] âš ï¸ [å®šæœŸè¯Šæ–­] æœ¬åœ°éŸ³é¢‘ tap å›è°ƒå¯èƒ½å·²åœæ­¢ï¼ˆè¶…è¿‡2ç§’æ— å›è°ƒï¼‰")
					}
					if timeSinceLastRemote > 2.0 && self.remoteAudioCallbackCount > 0 {
						print("[WebRTCConnector] âš ï¸ [å®šæœŸè¯Šæ–­] è¿œç¨‹éŸ³é¢‘ tap å›è°ƒå¯èƒ½å·²åœæ­¢ï¼ˆè¶…è¿‡2ç§’æ— å›è°ƒï¼‰")
					}
				}
				timer.resume()
				self.diagnosticTimer = timer
				
				print("========================================")
					
					continuation.resume()
					
				} catch {
					print("[WebRTCConnector] å¼€å§‹å½•åˆ¶å¤±è´¥: \(error)")
					continuation.resume(throwing: WebRTCError.failedToStartRecording(error))
				}
			}
		}
	}
	
	/// åœæ­¢å½•åˆ¶
	func stopRecording() {
		guard isRecording else { return }
		
		recordingQueue.async { [weak self] in
			guard let self = self else { return }
			
			// å–æ¶ˆè¯Šæ–­å®šæ—¶å™¨
			if let timer = self.diagnosticTimer {
				timer.cancel()
				self.diagnosticTimer = nil
			}
			
			// åœæ­¢éŸ³é¢‘å¼•æ“
			if let engine = self.audioEngine {
				engine.stop()
				// ç§»é™¤æ‰€æœ‰ tap
				engine.mainMixerNode.removeTap(onBus: 0)
				if let mixerNode = engine.attachedNodes.first(where: { $0 is AVAudioMixerNode }) as? AVAudioMixerNode {
					mixerNode.removeTap(onBus: 0)
				}
			}
			self.audioEngine = nil
			
			// æ¸…ç©ºéŸ³é¢‘ç¼“å†²åŒºé˜Ÿåˆ—
			self.bufferQueueLock.lock()
			let remainingSamples = self.audioBufferQueue.count
			self.audioBufferQueue.removeAll()
			self.bufferQueueLock.unlock()
			
			if remainingSamples > 0 {
				print("[WebRTCConnector] âš ï¸ åœæ­¢å½•åˆ¶æ—¶ï¼Œé˜Ÿåˆ—ä¸­è¿˜æœ‰ \(remainingSamples) ä¸ªæ ·æœ¬æœªå†™å…¥")
			}
			
			// ç­‰å¾…é˜Ÿåˆ—å¤„ç†å®Œæˆï¼ˆæœ€å¤šç­‰å¾…2ç§’ï¼‰
			if let writeQueue = self.audioWriteQueue {
				let semaphore = DispatchSemaphore(value: 0)
				writeQueue.async {
					// å¤„ç†å‰©ä½™çš„é˜Ÿåˆ—é¡¹
					self.processAudioWriteQueue()
					semaphore.signal()
				}
				_ = semaphore.wait(timeout: .now() + 2.0)
			}
			
			// å…³é—­æ–‡ä»¶å¥æŸ„
			if let fileHandle = self.fileHandle {
				fileHandle.synchronizeFile()
				fileHandle.closeFile()
				self.fileHandle = nil
			}
			
			// æ›´æ–° WAV æ–‡ä»¶å¤´
			if let fileURL = self.recordingURL {
				let finalDataSize = self.wavDataSize
				do {
					try self.updateWAVHeader(fileURL: fileURL, dataSize: finalDataSize)
				} catch {
					print("[WebRTCConnector] âš ï¸ æ›´æ–° WAV æ–‡ä»¶å¤´å¤±è´¥: \(error.localizedDescription)")
				}
				
				// è·å–æ–‡ä»¶ä¿¡æ¯
				let filePath = fileURL.path
				let fileName = fileURL.lastPathComponent
				
				// è·å–æ–‡ä»¶å¤§å°
				var fileSize: Int64 = 0
				if let attributes = try? FileManager.default.attributesOfItem(atPath: filePath),
				   let size = attributes[.size] as? Int64 {
					fileSize = size
				}
				
				// æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
				let fileSizeMB = Double(fileSize) / (1024 * 1024)
				let fileSizeKB = Double(fileSize) / 1024
				let fileSizeString = fileSizeMB >= 1.0 
					? String(format: "%.2f MB", fileSizeMB)
					: String(format: "%.2f KB", fileSizeKB)
				
				// è·å–æ–‡ä»¶åˆ›å»ºæ—¶é—´
				let creationDate = (try? FileManager.default.attributesOfItem(atPath: filePath))?[.creationDate] as? Date
				let dateFormatter = DateFormatter()
				dateFormatter.dateFormat = "yyyy-MM-dd HH:mm:ss"
				let dateString = creationDate != nil ? dateFormatter.string(from: creationDate!) : "æœªçŸ¥"
				
				// æ‰“å°è¯¦ç»†çš„æ–‡ä»¶ä¿¡æ¯
				print("========================================")
				print("[WebRTCConnector] å½•åˆ¶å®Œæˆ")
				print("========================================")
				print("æ–‡ä»¶å: \(fileName)")
				print("æ–‡ä»¶è·¯å¾„: \(filePath)")
				print("æ–‡ä»¶å¤§å°: \(fileSizeString) (\(fileSize) å­—èŠ‚)")
				print("åˆ›å»ºæ—¶é—´: \(dateString)")
				print("========================================")
			} else {
				print("[WebRTCConnector] å½•åˆ¶å®Œæˆï¼Œä½†æ–‡ä»¶URLä¸ºç©º")
			}
			
			self.audioWriteQueue = nil
			self.isRecording = false
			
			// é‡ç½®æ—¶é—´æˆ³å’Œç»Ÿè®¡ä¿¡æ¯
			self.timestampLock.lock()
			let finalFrames = self.totalFramesWritten
			let finalDataSize = self.wavDataSize
			let skippedFrames = self.skippedFramesCount
			let skippedLocal = self.skippedFramesCountLocal
			let skippedRemote = self.skippedFramesCountRemote
			self.recordingStartTime = .zero
			self.lastPresentationTime = .zero
			self.totalFramesWritten = 0
			self.wavDataSize = 0
			self.skippedFramesCount = 0
			self.skippedFramesCountLocal = 0
			self.skippedFramesCountRemote = 0
			self.timestampLock.unlock()
			
			// æ‰“å°å½•åˆ¶ç»Ÿè®¡ä¿¡æ¯
			if finalFrames > 0 {
				let durationSeconds = Double(finalFrames) / 24000.0 // 24000 Hz é‡‡æ ·ç‡
				print("[WebRTCConnector] ğŸ“Š å½•åˆ¶ç»Ÿè®¡:")
				print("  - æ€»å†™å…¥å¸§æ•°: \(finalFrames)")
				print("  - æ€»æ•°æ®å¤§å°: \(finalDataSize) å­—èŠ‚")
				print("  - æ€»æ—¶é•¿: \(String(format: "%.2f", durationSeconds)) ç§’")
				if skippedFrames > 0 {
					print("  - è·³è¿‡çš„å¸§æ•°: \(skippedFrames) (æœ¬åœ°: \(skippedLocal), è¿œç¨‹: \(skippedRemote))")
					let skipPercentage = Double(skippedFrames) / Double(finalFrames + skippedFrames) * 100.0
					print("  - è·³è¿‡æ¯”ä¾‹: \(String(format: "%.2f", skipPercentage))%")
				} else {
					print("  - è·³è¿‡çš„å¸§æ•°: 0 (æ‰€æœ‰å¸§éƒ½å·²æˆåŠŸå†™å…¥)")
				}
			}
		}
	}
	
	/// è¿æ¥è¿œç¨‹éŸ³é¢‘è½¨é“åˆ°éŸ³é¢‘å¼•æ“
	private func connectRemoteAudioToEngine() {
		// è¯Šæ–­æ—¥å¿—ï¼šè®°å½•è¿æ¥å°è¯•
		print("[WebRTCConnector] ğŸ” [è¿œç¨‹éŸ³é¢‘è¿æ¥] å°è¯•è¿æ¥è¿œç¨‹éŸ³é¢‘è½¨é“åˆ°å¼•æ“")
		
		guard let remoteTrack = remoteAudioTrack else {
			print("[WebRTCConnector] âš ï¸ [è¿œç¨‹éŸ³é¢‘è¿æ¥] è¿œç¨‹éŸ³é¢‘è½¨é“ä¸å­˜åœ¨")
			return
		}
		
		print("[WebRTCConnector] ğŸ” [è¿œç¨‹éŸ³é¢‘è¿æ¥] è¿œç¨‹éŸ³é¢‘è½¨é“ä¿¡æ¯:")
		print("  - è½¨é“ID: \(remoteTrack.trackId)")
		print("  - æ˜¯å¦å¯ç”¨: \(remoteTrack.isEnabled)")
		print("  - çŠ¶æ€: \(remoteTrack.readyState.rawValue)")
		
		guard let engine = audioEngine, let playerNode = remotePlayerNode else {
			print("[WebRTCConnector] âš ï¸ [è¿œç¨‹éŸ³é¢‘è¿æ¥] éŸ³é¢‘å¼•æ“æˆ–è¿œç¨‹æ’­æ”¾èŠ‚ç‚¹ä¸å­˜åœ¨")
			return
		}
		
		print("[WebRTCConnector] ğŸ” [è¿œç¨‹éŸ³é¢‘è¿æ¥] éŸ³é¢‘å¼•æ“çŠ¶æ€:")
		print("  - æ˜¯å¦è¿è¡Œ: \(engine.isRunning)")
		print("  - å·²é™„åŠ èŠ‚ç‚¹æ•°: \(engine.attachedNodes.count)")
		
		// æ£€æŸ¥è¿œç¨‹éŸ³é¢‘è½¨é“æ˜¯å¦å¯ç”¨
		if !remoteTrack.isEnabled {
			print("[WebRTCConnector] âš ï¸ [è¿œç¨‹éŸ³é¢‘è¿æ¥] è¿œç¨‹éŸ³é¢‘è½¨é“æœªå¯ç”¨ï¼Œå°è¯•å¯ç”¨")
			remoteTrack.isEnabled = true
		}
		
		// æ³¨æ„ï¼šWebRTC çš„è¿œç¨‹éŸ³é¢‘è½¨é“é€šè¿‡ç³»ç»ŸéŸ³é¢‘è¾“å‡ºè‡ªåŠ¨æ’­æ”¾
		// ç”±äº LiveKitWebRTC å¯èƒ½ä¸ç›´æ¥æä¾›éŸ³é¢‘æ•°æ®æµ APIï¼Œæˆ‘ä»¬éœ€è¦ï¼š
		// 1. ç¡®ä¿è¿œç¨‹éŸ³é¢‘è½¨é“å·²å¯ç”¨
		// 2. è¿œç¨‹éŸ³é¢‘ä¼šé€šè¿‡ç³»ç»ŸéŸ³é¢‘è¾“å‡ºæ’­æ”¾
		// 3. æˆ‘ä»¬çš„ finalMixerNode å·²ç»è¿æ¥äº†æœ¬åœ°éŸ³é¢‘å’Œè¿œç¨‹æ’­æ”¾èŠ‚ç‚¹
		// 4. å¦‚æœè¿œç¨‹éŸ³é¢‘é€šè¿‡ç³»ç»Ÿæ’­æ”¾ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡å…¶ä»–æ–¹å¼æ•è·ï¼ˆå¦‚ AVAudioSession è·¯ç”±ï¼‰
		
		// ç›®å‰ï¼Œè¿œç¨‹éŸ³é¢‘æ’­æ”¾èŠ‚ç‚¹å·²è¿æ¥åˆ° finalMixerNode
		// ä½†æˆ‘ä»¬éœ€è¦æ‰¾åˆ°æ–¹æ³•å°†è¿œç¨‹éŸ³é¢‘æ•°æ®è¾“å…¥åˆ° playerNode
		// ç”±äº WebRTC éŸ³é¢‘è½¨é“å¯èƒ½ä¸ç›´æ¥æä¾›æ•°æ®æµï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦ï¼š
		// - ä½¿ç”¨ AVAudioSession çš„è·¯ç”±æ¥æ•è·ç³»ç»ŸéŸ³é¢‘è¾“å‡º
		// - æˆ–è€…ç­‰å¾… WebRTC æä¾›éŸ³é¢‘æ•°æ®å›è°ƒ
		
		print("[WebRTCConnector] âš ï¸ [è¿œç¨‹éŸ³é¢‘è¿æ¥] æ³¨æ„ï¼šWebRTC è¿œç¨‹éŸ³é¢‘è½¨é“å¯èƒ½ä¸ç›´æ¥æä¾›éŸ³é¢‘æ•°æ®æµ")
		print("[WebRTCConnector] ğŸ” [è¿œç¨‹éŸ³é¢‘è¿æ¥] è¿œç¨‹éŸ³é¢‘æ’­æ”¾èŠ‚ç‚¹å·²è¿æ¥åˆ° finalMixerNode")
		print("[WebRTCConnector] ğŸ” [è¿œç¨‹éŸ³é¢‘è¿æ¥] éœ€è¦æ‰¾åˆ°æ–¹æ³•å°†è¿œç¨‹éŸ³é¢‘æ•°æ®è¾“å…¥åˆ° playerNode")
		
		// å¯åŠ¨è¿œç¨‹éŸ³é¢‘æ’­æ”¾èŠ‚ç‚¹ï¼ˆå³ä½¿æ²¡æœ‰æ•°æ®ï¼Œä¹Ÿè¦å¯åŠ¨ä»¥ä¿æŒè¿æ¥ï¼‰
		if !playerNode.isPlaying {
			playerNode.play()
			print("[WebRTCConnector] âœ… [è¿œç¨‹éŸ³é¢‘è¿æ¥] è¿œç¨‹éŸ³é¢‘æ’­æ”¾èŠ‚ç‚¹å·²å¯åŠ¨")
		}
		
		// è¯Šæ–­ï¼šæ£€æŸ¥ finalMixerNode çš„è¾“å…¥è¿æ¥çŠ¶æ€
		if let finalMixerNode = engine.attachedNodes.first(where: { $0 is AVAudioMixerNode && $0 !== engine.mainMixerNode }) as? AVAudioMixerNode {
			print("[WebRTCConnector] ğŸ” [è¿œç¨‹éŸ³é¢‘è¿æ¥] finalMixerNode è¾“å…¥è¿æ¥:")
			print("  - è¾“å…¥æ•°é‡: \(finalMixerNode.numberOfInputs)")
			for bus in 0..<finalMixerNode.numberOfInputs {
				let inputFormat = finalMixerNode.inputFormat(forBus: bus)
				print("  - Bus \(bus) é‡‡æ ·ç‡: \(inputFormat.sampleRate) Hz, å£°é“æ•°: \(inputFormat.channelCount)")
			}
		}
		
		// é‡è¦æç¤ºï¼šç”±äº WebRTC çš„è¿œç¨‹éŸ³é¢‘è½¨é“é€šè¿‡ç³»ç»ŸéŸ³é¢‘è¾“å‡ºè‡ªåŠ¨æ’­æ”¾ï¼Œ
		// å¯èƒ½ä¸ç›´æ¥è¿›å…¥æˆ‘ä»¬çš„ AVAudioEngineã€‚å¦‚æœè¿œç¨‹éŸ³é¢‘æ²¡æœ‰è¿›å…¥å¼•æ“ï¼Œ
		// æ··åˆéŸ³é¢‘å°†åªåŒ…å«æœ¬åœ°éŸ³é¢‘ã€‚è¿™éœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥ WebRTC éŸ³é¢‘è·¯ç”±æœºåˆ¶ã€‚
		print("[WebRTCConnector] âš ï¸ [è¿œç¨‹éŸ³é¢‘è¿æ¥] é‡è¦æç¤ºï¼š")
		print("  - WebRTC è¿œç¨‹éŸ³é¢‘å¯èƒ½é€šè¿‡ç³»ç»ŸéŸ³é¢‘è¾“å‡ºæ’­æ”¾ï¼Œä¸ç»è¿‡æˆ‘ä»¬çš„ AVAudioEngine")
		print("  - å¦‚æœè¿œç¨‹éŸ³é¢‘æ²¡æœ‰è¿›å…¥å¼•æ“ï¼Œæ··åˆéŸ³é¢‘å°†åªåŒ…å«æœ¬åœ°éŸ³é¢‘")
		print("  - éœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥ WebRTC éŸ³é¢‘è·¯ç”±æœºåˆ¶æˆ–ä½¿ç”¨å…¶ä»–æ•è·æ–¹æ³•")
		
		print("[WebRTCConnector] âœ… [è¿œç¨‹éŸ³é¢‘è¿æ¥] è¿œç¨‹éŸ³é¢‘è½¨é“è¿æ¥æ£€æŸ¥å®Œæˆ")
	}
	
	/// å†™å…¥ WAV æ–‡ä»¶å¤´ï¼ˆ44 å­—èŠ‚ï¼‰
	/// - Parameters:
	///   - fileURL: æ–‡ä»¶ URL
	///   - sampleRate: é‡‡æ ·ç‡ï¼ˆé»˜è®¤ 24000ï¼‰
	///   - channels: å£°é“æ•°ï¼ˆé»˜è®¤ 1ï¼‰
	///   - bitsPerSample: ä½æ·±åº¦ï¼ˆé»˜è®¤ 16ï¼‰
	///   - dataSize: æ•°æ®å¤§å°ï¼ˆåˆå§‹ä¸º 0ï¼Œåœæ­¢å½•åˆ¶æ—¶æ›´æ–°ï¼‰
	private func writeWAVHeader(to fileURL: URL, sampleRate: UInt32 = 24000, channels: UInt16 = 1, bitsPerSample: UInt16 = 16, dataSize: UInt32 = 0) throws {
		var header = Data(capacity: 44)
		
		// RIFF chunk descriptor (12 bytes)
		header.append("RIFF".data(using: .ascii)!)
		let fileSize = UInt32(36 + dataSize) // 36 = 44 - 8 (chunk size + format + data chunk header)
		header.append(contentsOf: withUnsafeBytes(of: fileSize.littleEndian) { Data($0) })
		header.append("WAVE".data(using: .ascii)!)
		
		// fmt sub-chunk (24 bytes)
		header.append("fmt ".data(using: .ascii)!)
		let fmtSize: UInt32 = 16 // PCM format
		header.append(contentsOf: withUnsafeBytes(of: fmtSize.littleEndian) { Data($0) })
		let audioFormat: UInt16 = 1 // PCM
		header.append(contentsOf: withUnsafeBytes(of: audioFormat.littleEndian) { Data($0) })
		header.append(contentsOf: withUnsafeBytes(of: channels.littleEndian) { Data($0) })
		header.append(contentsOf: withUnsafeBytes(of: sampleRate.littleEndian) { Data($0) })
		let byteRate = UInt32(sampleRate * UInt32(channels) * UInt32(bitsPerSample) / 8)
		header.append(contentsOf: withUnsafeBytes(of: byteRate.littleEndian) { Data($0) })
		let blockAlign = UInt16(channels * bitsPerSample / 8)
		header.append(contentsOf: withUnsafeBytes(of: blockAlign.littleEndian) { Data($0) })
		header.append(contentsOf: withUnsafeBytes(of: bitsPerSample.littleEndian) { Data($0) })
		
		// data sub-chunk header (8 bytes)
		header.append("data".data(using: .ascii)!)
		header.append(contentsOf: withUnsafeBytes(of: dataSize.littleEndian) { Data($0) })
		
		// å†™å…¥æ–‡ä»¶å¤´
		try header.write(to: fileURL)
		print("[WebRTCConnector] âœ… WAV æ–‡ä»¶å¤´å·²å†™å…¥ (44 å­—èŠ‚)")
		print("  - é‡‡æ ·ç‡: \(sampleRate) Hz")
		print("  - å£°é“æ•°: \(channels)")
		print("  - ä½æ·±åº¦: \(bitsPerSample) ä½")
		print("  - æ•°æ®å¤§å°: \(dataSize) å­—èŠ‚")
	}
	
	/// æ›´æ–° WAV æ–‡ä»¶å¤´ä¸­çš„æ•°æ®å¤§å°å­—æ®µ
	/// - Parameters:
	///   - fileURL: æ–‡ä»¶ URL
	///   - dataSize: å®é™…å†™å…¥çš„ PCM æ•°æ®å¤§å°
	private func updateWAVHeader(fileURL: URL, dataSize: UInt32) throws {
		guard let fileHandle = try? FileHandle(forUpdating: fileURL) else {
			throw NSError(domain: "WebRTC", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ— æ³•æ‰“å¼€æ–‡ä»¶ä»¥æ›´æ–°æ–‡ä»¶å¤´"])
		}
		defer { fileHandle.closeFile() }
		
		// æ›´æ–° RIFF chunk size (åç§» 4)
		fileHandle.seek(toFileOffset: 4)
		let fileSize = UInt32(36 + dataSize)
		var fileSizeBytes = withUnsafeBytes(of: fileSize.littleEndian) { Data($0) }
		fileHandle.write(fileSizeBytes)
		
		// æ›´æ–° data chunk size (åç§» 40)
		fileHandle.seek(toFileOffset: 40)
		var dataSizeBytes = withUnsafeBytes(of: dataSize.littleEndian) { Data($0) }
		fileHandle.write(dataSizeBytes)
		
		print("[WebRTCConnector] âœ… WAV æ–‡ä»¶å¤´å·²æ›´æ–°")
		print("  - æ–‡ä»¶å¤§å°: \(fileSize + 8) å­—èŠ‚")
		print("  - æ•°æ®å¤§å°: \(dataSize) å­—èŠ‚")
	}
	
	/// åˆ†æéŸ³é¢‘æ•°æ®çš„ç»Ÿè®¡ä¿¡æ¯
	/// - Parameter buffer: AVAudioPCMBuffer
	/// - Returns: (æœ€å¤§å€¼, æœ€å°å€¼, RMSå€¼, æ˜¯å¦é™éŸ³)
	private func analyzeAudioBuffer(_ buffer: AVAudioPCMBuffer) -> (max: Float, min: Float, rms: Float, isSilent: Bool) {
		guard let floatChannelData = buffer.floatChannelData else {
			return (0, 0, 0, true)
		}
		
		let frameLength = Int(buffer.frameLength)
		let channelCount = Int(buffer.format.channelCount)
		
		var maxValue: Float = -Float.greatestFiniteMagnitude
		var minValue: Float = Float.greatestFiniteMagnitude
		var sumSquares: Float = 0.0
		var totalSamples = 0
		
		for channel in 0..<channelCount {
			let channelData = floatChannelData[channel]
			for frame in 0..<frameLength {
				let value = channelData[frame]
				maxValue = max(maxValue, value)
				minValue = min(minValue, value)
				sumSquares += value * value
				totalSamples += 1
			}
		}
		
		let rms = totalSamples > 0 ? sqrt(sumSquares / Float(totalSamples)) : 0.0
		// å¦‚æœ RMS å€¼å°äº 0.001ï¼Œè®¤ä¸ºæ˜¯é™éŸ³
		let isSilent = rms < 0.001
		
		return (maxValue, minValue, rms, isSilent)
	}
	
	/// å°† Float32 PCM è½¬æ¢ä¸º Int16 PCM
	/// - Parameter floatBuffer: Float32 PCM ç¼“å†²åŒº
	/// - Returns: Int16 PCM æ•°æ®
	private func convertFloat32ToInt16(floatBuffer: AVAudioPCMBuffer) -> Data? {
		guard let floatChannelData = floatBuffer.floatChannelData else {
			return nil
		}
		
		let frameLength = Int(floatBuffer.frameLength)
		let channelCount = Int(floatBuffer.format.channelCount)
		// å¯¹äºå•å£°é“ï¼Œåªéœ€è¦ frameLength * 2 å­—èŠ‚ï¼›å¯¹äºå¤šå£°é“ï¼Œéœ€è¦ frameLength * channelCount * 2 å­—èŠ‚
		var int16Data = Data(capacity: frameLength * channelCount * 2) // 2 bytes per Int16
		
		// å¤„ç†æ¯ä¸ªé€šé“çš„æ•°æ®
		for channel in 0..<channelCount {
			let channelData = floatChannelData[channel]
			for frame in 0..<frameLength {
				let floatValue = channelData[frame]
				// é™åˆ¶èŒƒå›´å¹¶è½¬æ¢ä¸º Int16ï¼ˆ-1.0 åˆ° 1.0 æ˜ å°„åˆ° -32768 åˆ° 32767ï¼‰
				let clampedValue = max(-1.0, min(1.0, floatValue))
				let int16Value = Int16(clampedValue * 32767.0)
				var int16Bytes = withUnsafeBytes(of: int16Value.littleEndian) { Data($0) }
				int16Data.append(int16Bytes)
			}
		}
		
		return int16Data
	}

	/// è·å–ä¸‹ä¸€ä¸ªæ—¶é—´æˆ³ï¼ˆçº¿ç¨‹å®‰å…¨ï¼Œç»Ÿä¸€ç®¡ç†ï¼‰
	private func getNextPresentationTimeStamp(duration: CMTime) -> CMTime {
		timestampLock.lock()
		defer { timestampLock.unlock() }
		
		let previousLastTime = lastPresentationTime
		let durationSeconds = CMTimeGetSeconds(duration)
		
		let presentationTimeStamp: CMTime
		if lastPresentationTime == .zero {
			// ç¬¬ä¸€ä¸ªæ ·æœ¬ï¼Œä»é›¶å¼€å§‹
			presentationTimeStamp = .zero
			// æ›´æ–°æœ€åçš„æ—¶é—´æˆ³ä¸ºå½“å‰æ—¶é—´æˆ³åŠ ä¸ŠæŒç»­æ—¶é—´
			lastPresentationTime = presentationTimeStamp + duration
			print("[WebRTCConnector] â±ï¸ æ—¶é—´æˆ³ç®¡ç†å™¨: ç¬¬ä¸€ä¸ªæ ·æœ¬ï¼ŒPTS=0, æ—¶é•¿=\(String(format: "%.4f", durationSeconds))ç§’")
		} else {
			// åŸºäºä¸Šä¸€ä¸ªæ—¶é—´æˆ³ï¼ˆå·²ç»æ˜¯ä¸Šä¸€ä¸ªæ ·æœ¬çš„ç»“æŸæ—¶é—´ï¼‰
			presentationTimeStamp = lastPresentationTime
			let previousTimeSeconds = CMTimeGetSeconds(previousLastTime)
			// æ›´æ–°æœ€åçš„æ—¶é—´æˆ³ä¸ºå½“å‰æ—¶é—´æˆ³åŠ ä¸ŠæŒç»­æ—¶é—´
			lastPresentationTime = presentationTimeStamp + duration
			let newTimeSeconds = CMTimeGetSeconds(lastPresentationTime)
			

			timestampCallCount += 1
			if timestampCallCount % 100 == 0 {
				let timeGap = newTimeSeconds - previousTimeSeconds
				print("[WebRTCConnector] ğŸ” [æ—¶é—´æˆ³] è·å–æ—¶é—´æˆ³ #\(timestampCallCount) - PTS: \(String(format: "%.4f", previousTimeSeconds))ç§’ -> \(String(format: "%.4f", newTimeSeconds))ç§’, å¢é‡: \(String(format: "%.4f", timeGap))ç§’, æ ·æœ¬æ—¶é•¿: \(String(format: "%.4f", durationSeconds))ç§’")
				
				// æ£€æŸ¥æ—¶é—´æˆ³æ˜¯å¦æœ‰é—´éš™ï¼ˆå¢é‡åº”è¯¥ç­‰äºæ ·æœ¬æ—¶é•¿ï¼‰
				let gapDifference = abs(timeGap - durationSeconds)
				if gapDifference > 0.001 { // å…è®¸1msçš„è¯¯å·®
					print("[WebRTCConnector] âš ï¸ [æ—¶é—´æˆ³] æ—¶é—´æˆ³é—´éš™å¼‚å¸¸ - æœŸæœ›å¢é‡: \(String(format: "%.4f", durationSeconds))ç§’, å®é™…å¢é‡: \(String(format: "%.4f", timeGap))ç§’, å·®å¼‚: \(String(format: "%.4f", gapDifference))ç§’")
				}
			}
		}
		
		totalFramesWritten += Int64(duration.value)
		
		// æ¯100ä¸ªæ ·æœ¬æ‰“å°ä¸€æ¬¡ç»Ÿè®¡ä¿¡æ¯ï¼ˆé¿å…æ—¥å¿—è¿‡å¤šï¼‰
		if totalFramesWritten % 100 == 0 {
			let currentTime = CMTimeGetSeconds(lastPresentationTime)
			print("[WebRTCConnector] ğŸ“Š æ—¶é—´æˆ³ç»Ÿè®¡: æ€»å¸§æ•°=\(totalFramesWritten), å½“å‰æ—¶é—´=\(String(format: "%.2f", currentTime))ç§’")
		}
		
		return presentationTimeStamp
	}
	
	/// å°† AVAudioPCMBuffer è½¬æ¢ä¸º CMSampleBuffer
	private func createSampleBuffer(from pcmBuffer: AVAudioPCMBuffer, time: AVAudioTime, source: String = "æœªçŸ¥") -> CMSampleBuffer? {
		// æ›´æ–°è°ƒç”¨è®¡æ•°
		if source == "æœ¬åœ°" {
			createSampleBufferCountLocal += 1
		} else if source == "è¿œç¨‹" {
			createSampleBufferCountRemote += 1
		}
		
		let callCount = source == "æœ¬åœ°" ? createSampleBufferCountLocal : createSampleBufferCountRemote
		
		// è¯Šæ–­æ—¥å¿—ï¼šè®°å½•æ–¹æ³•è°ƒç”¨ï¼ˆå‰100æ¬¡æ¯æ¬¡éƒ½è®°å½•ï¼Œä¹‹åæ¯100æ¬¡è®°å½•ä¸€æ¬¡ï¼‰
		if callCount <= 100 || callCount % 100 == 0 {
			print("[WebRTCConnector] ğŸ” [createSampleBuffer] [\(source)] è°ƒç”¨ #\(callCount) - å¼€å§‹åˆ›å»º sampleBuffer")
		}
		
		var sampleBuffer: CMSampleBuffer?
		var formatDescription: CMFormatDescription?
		
		let sampleRate = pcmBuffer.format.sampleRate
		let timescale = Int32(sampleRate)
		let frameLength = pcmBuffer.frameLength
		let channelCount = pcmBuffer.format.channelCount
		
		// è¯Šæ–­æ—¥å¿—ï¼šè®°å½•è¾“å…¥å‚æ•°ï¼ˆå‰10æ¬¡è¯¦ç»†è®°å½•ï¼‰
		if callCount <= 10 {
			print("[WebRTCConnector] ğŸ” [createSampleBuffer] [\(source)] è¾“å…¥å‚æ•° - é‡‡æ ·ç‡: \(sampleRate)Hz, å¸§æ•°: \(frameLength), å£°é“æ•°: \(channelCount)")
		}
		
		// éªŒè¯ buffer å‚æ•°
		if frameLength == 0 {
			print("[WebRTCConnector] âŒ [\(source)] createSampleBuffer: frameLength ä¸º 0")
			return nil
		}
		
		if sampleRate <= 0 {
			print("[WebRTCConnector] âŒ [\(source)] createSampleBuffer: é‡‡æ ·ç‡æ— æ•ˆ: \(sampleRate)")
			return nil
		}
		
		// åˆ›å»ºæ ¼å¼æè¿°
		var asbd = pcmBuffer.format.streamDescription.pointee
		
		// åªåœ¨ç¬¬ä¸€æ¬¡æˆ–å‡ºé”™æ—¶æ‰“å°è¯¦ç»†ä¿¡æ¯ï¼ˆé¿å…æ—¥å¿—è¿‡å¤šï¼‰
        var firstCallMap: [String: Bool] = [:]
		if firstCallMap[source] != true {
			print("[WebRTCConnector] ğŸ“Š [\(source)] åˆ›å»ºæ ¼å¼æè¿°:")
			print("  - é‡‡æ ·ç‡: \(sampleRate) Hz")
			print("  - å¸§æ•°: \(frameLength)")
			print("  - å£°é“æ•°: \(channelCount)")
			print("  - æ ¼å¼ID: \(asbd.mFormatID)")
			print("  - æ¯å¸§å­—èŠ‚æ•°: \(asbd.mBytesPerFrame)")
			print("  - æ¯åŒ…å¸§æ•°: \(asbd.mFramesPerPacket)")
			firstCallMap[source] = true
		}
		
		let status = CMAudioFormatDescriptionCreate(
			allocator: kCFAllocatorDefault,
			asbd: &asbd,
			layoutSize: 0,
			layout: nil,
			magicCookieSize: 0,
			magicCookie: nil,
			extensions: nil,
			formatDescriptionOut: &formatDescription
		)
		
		guard status == noErr, let formatDesc = formatDescription else {
			print("[WebRTCConnector] âŒ [\(source)] åˆ›å»ºæ ¼å¼æè¿°å¤±è´¥: status=\(status), é‡‡æ ·ç‡=\(sampleRate)Hz, å¸§æ•°=\(frameLength)")
			return nil
		}
		
		// è®¡ç®—æŒç»­æ—¶é—´
		let duration = CMTime(value: Int64(frameLength), timescale: timescale)
		
		// ä½¿ç”¨ç»Ÿä¸€çš„æ—¶é—´æˆ³ç®¡ç†å™¨è·å–æ—¶é—´æˆ³ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
		let presentationTimeStamp = getNextPresentationTimeStamp(duration: duration)
		
		var timingInfo = CMSampleTimingInfo(
			duration: duration,
			presentationTimeStamp: presentationTimeStamp,
			decodeTimeStamp: .invalid
		)
		
		let data = pcmBuffer.audioBufferList.pointee.mBuffers.mData
		let dataSize = pcmBuffer.audioBufferList.pointee.mBuffers.mDataByteSize
		
		guard let dataPointer = data else {
			print("[WebRTCConnector] âŒ [\(source)] æ•°æ®æŒ‡é’ˆä¸º nil, æ•°æ®å¤§å°=\(dataSize)å­—èŠ‚")
			return nil
		}
		
		var dataBlock: CMBlockBuffer?
		// ä½¿ç”¨ CMBlockBufferCreateWithMemoryBlock çš„å®Œæ•´ç‰ˆæœ¬
		let blockBufferStatus = CMBlockBufferCreateWithMemoryBlock(
			allocator: kCFAllocatorDefault,
			memoryBlock: nil,
			blockLength: Int(dataSize),
			blockAllocator: nil,
			customBlockSource: nil,
			offsetToData: 0,
			dataLength: Int(dataSize),
			flags: 0,
			blockBufferOut: &dataBlock
		)
		
		guard blockBufferStatus == noErr, let blockBuffer = dataBlock else {
			print("[WebRTCConnector] âŒ [\(source)] åˆ›å»º CMBlockBuffer å¤±è´¥: status=\(blockBufferStatus), æ•°æ®å¤§å°=\(dataSize)å­—èŠ‚")
			return nil
		}
		
		// å¤åˆ¶æ•°æ®åˆ° block buffer
		let replaceStatus = CMBlockBufferReplaceDataBytes(
			with: dataPointer,
			blockBuffer: blockBuffer,
			offsetIntoDestination: 0,
			dataLength: Int(dataSize)
		)
		
		guard replaceStatus == noErr else {
			print("[WebRTCConnector] âŒ [\(source)] å¤åˆ¶æ•°æ®åˆ° CMBlockBuffer å¤±è´¥: status=\(replaceStatus), æ•°æ®å¤§å°=\(dataSize)å­—èŠ‚")
			return nil
		}
		
		let sampleBufferStatus = CMSampleBufferCreate(
			allocator: kCFAllocatorDefault,
			dataBuffer: blockBuffer,
			dataReady: true,
			makeDataReadyCallback: nil,
            refcon: nil,
			formatDescription: formatDesc,
            sampleCount: CMItemCount(frameLength),
			sampleTimingEntryCount: 1,
			sampleTimingArray: &timingInfo,
			sampleSizeEntryCount: 0,
			sampleSizeArray: nil,
			sampleBufferOut: &sampleBuffer
		)
		
		guard sampleBufferStatus == noErr else {
			print("[WebRTCConnector] âŒ [\(source)] åˆ›å»º CMSampleBuffer å¤±è´¥: status=\(sampleBufferStatus), å¸§æ•°=\(frameLength), é‡‡æ ·ç‡=\(sampleRate)Hz")
			return nil
		}
		
		// è¯Šæ–­æ—¥å¿—ï¼šè®°å½•æˆåŠŸåˆ›å»ºï¼ˆå‰100æ¬¡æ¯æ¬¡éƒ½è®°å½•ï¼Œä¹‹åæ¯100æ¬¡è®°å½•ä¸€æ¬¡ï¼‰
		if callCount <= 100 || callCount % 100 == 0 {
			let pts = CMSampleBufferGetPresentationTimeStamp(sampleBuffer!)
			let duration = CMSampleBufferGetDuration(sampleBuffer!)
			print("[WebRTCConnector] âœ… [createSampleBuffer] [\(source)] æˆåŠŸåˆ›å»º #\(callCount) - PTS: \(CMTimeGetSeconds(pts))ç§’, æ—¶é•¿: \(CMTimeGetSeconds(duration))ç§’, å¸§æ•°: \(frameLength)")
		}
		
		return sampleBuffer
	}
	
	/// å°†éŸ³é¢‘ PCM ç¼“å†²åŒºæ”¾å…¥å†™å…¥é˜Ÿåˆ—
	private func enqueueAudioPCMBuffer(_ pcmBuffer: AVAudioPCMBuffer, source: String) {
		bufferQueueLock.lock()
		defer { bufferQueueLock.unlock() }
		
		let queueSizeBefore = audioBufferQueue.count
		// åˆ›å»º buffer çš„å‰¯æœ¬ä»¥é¿å…å†…å­˜é—®é¢˜
		guard let bufferCopy = AVAudioPCMBuffer(pcmFormat: pcmBuffer.format, frameCapacity: pcmBuffer.frameCapacity) else {
			print("[WebRTCConnector] âŒ [\(source)] æ— æ³•åˆ›å»º buffer å‰¯æœ¬")
			return
		}
		bufferCopy.frameLength = pcmBuffer.frameLength
		if let srcChannelData = pcmBuffer.floatChannelData, let dstChannelData = bufferCopy.floatChannelData {
			for channel in 0..<Int(pcmBuffer.format.channelCount) {
				memcpy(dstChannelData[channel], srcChannelData[channel], Int(pcmBuffer.frameLength) * MemoryLayout<Float>.size)
			}
		}
		
		audioBufferQueue.append((pcmBuffer: bufferCopy, source: source))
		let queueSizeAfter = audioBufferQueue.count
		
		// æ›´æ–°å…¥é˜Ÿè®¡æ•°
		if source == "æœ¬åœ°" {
			enqueueCountLocal += 1
		} else if source == "è¿œç¨‹" {
			enqueueCountRemote += 1
		}
		
		let currentCount = source == "æœ¬åœ°" ? enqueueCountLocal : enqueueCountRemote
		
		// è¯Šæ–­æ—¥å¿—ï¼šè®°å½•å…¥é˜Ÿæ“ä½œï¼ˆå‰10æ¬¡å¼ºåˆ¶è®°å½•ï¼Œä¹‹åæ¯50æ¬¡è®°å½•ä¸€æ¬¡ï¼‰
		let shouldLog = currentCount <= 10 || currentCount % 50 == 0
		if shouldLog {
			let frameCount = Int(pcmBuffer.frameLength)
			let sampleRate = pcmBuffer.format.sampleRate
			let duration = Double(frameCount) / sampleRate
			print("[WebRTCConnector] ğŸ” [é˜Ÿåˆ—å…¥é˜Ÿ] [\(source)] æ ·æœ¬ #\(currentCount) - é˜Ÿåˆ—å¤§å°: \(queueSizeBefore) -> \(queueSizeAfter), å¸§æ•°: \(frameCount), æ—¶é•¿: \(String(format: "%.4f", duration))ç§’")
		}
		
		// å¦‚æœé˜Ÿåˆ—è¿‡å¤§ï¼Œæ‰“å°è­¦å‘Šï¼ˆè¶…è¿‡100ä¸ªæ ·æœ¬ï¼Œçº¦4ç§’çš„éŸ³é¢‘ï¼‰
		if queueSizeAfter > 100 {
			print("[WebRTCConnector] âš ï¸ éŸ³é¢‘é˜Ÿåˆ—ç§¯å‹: \(queueSizeAfter) ä¸ªæ ·æœ¬å¾…å†™å…¥ (æ¥æº: \(source))")
		}
		
		// è§¦å‘é˜Ÿåˆ—å¤„ç†ï¼ˆå¦‚æœé˜Ÿåˆ—å¤„ç†æœªåœ¨è¿›è¡Œä¸­ï¼‰
		if !isProcessingWriteQueue, let writeQueue = audioWriteQueue {
			isProcessingWriteQueue = true
			writeQueue.async { [weak self] in
				self?.processAudioWriteQueue()
				self?.isProcessingWriteQueue = false
			}
		}
	}
	
	/// å¤„ç†éŸ³é¢‘å†™å…¥é˜Ÿåˆ—ï¼ˆå°† Float32 PCM è½¬æ¢ä¸º Int16 å¹¶å†™å…¥æ–‡ä»¶ï¼‰
	private func processAudioWriteQueue() {
		guard let fileHandle = fileHandle, isRecording else {
			return
		}
		
		// è¯Šæ–­æ—¥å¿—ï¼šè®°å½•å¤„ç†å¼€å§‹æ—¶çš„çŠ¶æ€
		bufferQueueLock.lock()
		let initialQueueSize = audioBufferQueue.count
		bufferQueueLock.unlock()
		
		// æ¯å¤„ç†50æ¬¡æ‰“å°ä¸€æ¬¡çŠ¶æ€ï¼ˆé¿å…æ—¥å¿—è¿‡å¤šï¼‰
		processQueueCount += 1
		// å‰10æ¬¡æˆ–æ¯5000æ¬¡è®°å½•ä¸€æ¬¡
		if processQueueCount <= 10 || processQueueCount % timestampCallFlag == 0 {
			print("[WebRTCConnector] ğŸ” [é˜Ÿåˆ—å¤„ç†] å¼€å§‹å¤„ç† #\(processQueueCount) - é˜Ÿåˆ—å¤§å°: \(initialQueueSize)")
		}
		
		var processedInThisCall = 0
		// æŒç»­å¤„ç†é˜Ÿåˆ—ç›´åˆ°ä¸ºç©º
		while true {
			// ä»é˜Ÿåˆ—ä¸­å–å‡ºä¸€ä¸ªæ ·æœ¬
			bufferQueueLock.lock()
			guard !audioBufferQueue.isEmpty else {
				bufferQueueLock.unlock()
				// è¯Šæ–­æ—¥å¿—ï¼šè®°å½•é˜Ÿåˆ—ä¸ºç©ºï¼ˆå‰10æ¬¡æˆ–æ¯5000æ¬¡è®°å½•ä¸€æ¬¡ï¼‰
				if processQueueCount <= 10 || processQueueCount % timestampCallFlag == 0 {
					print("[WebRTCConnector] ğŸ” [é˜Ÿåˆ—å¤„ç†] é˜Ÿåˆ—ä¸ºç©ºï¼Œé€€å‡ºå¤„ç†å¾ªç¯ - å¤„ç†#\(processQueueCount), æœ¬æ¬¡å·²å¤„ç†: \(processedInThisCall) ä¸ªæ ·æœ¬")
				}
				break
			}
			
			let queueSizeBeforeDequeue = audioBufferQueue.count
			let item = audioBufferQueue.removeFirst()
			let queueSizeAfterDequeue = audioBufferQueue.count
			bufferQueueLock.unlock()
			
			processedInThisCall += 1
			
			// è·å– buffer ä¿¡æ¯ç”¨äºæ—¥å¿—
			let frameCount = Int(item.pcmBuffer.frameLength)
			let sampleRate = item.pcmBuffer.format.sampleRate
			let duration = Double(frameCount) / sampleRate
			
			// è¯Šæ–­æ—¥å¿—ï¼šè®°å½•å‡ºé˜Ÿæ“ä½œï¼ˆå‰10æ¬¡å¼ºåˆ¶è®°å½•ï¼Œä¹‹åæ¯50æ¬¡è®°å½•ä¸€æ¬¡ï¼‰
			let shouldLogDequeue = processedInThisCall <= 10 || processedInThisCall % 50 == 0 || processQueueCount <= 10
			if shouldLogDequeue {
				print("[WebRTCConnector] ğŸ” [é˜Ÿåˆ—å‡ºé˜Ÿ] [\(item.source)] æ ·æœ¬ #\(processedInThisCall) (å¤„ç†#\(processQueueCount)) - é˜Ÿåˆ—å¤§å°: \(queueSizeBeforeDequeue) -> \(queueSizeAfterDequeue), å¸§æ•°: \(frameCount), æ—¶é•¿: \(String(format: "%.4f", duration))ç§’")
			}
			
			// å°† Float32 PCM è½¬æ¢ä¸º Int16 PCM
			guard let int16Data = convertFloat32ToInt16(floatBuffer: item.pcmBuffer) else {
				print("[WebRTCConnector] âŒ [\(item.source)] è½¬æ¢ Float32 åˆ° Int16 å¤±è´¥")
				continue
			}
			
			// å†™å…¥æ–‡ä»¶
			fileHandle.write(int16Data)
			
			// æ›´æ–°æ•°æ®å¤§å°è®¡æ•°å™¨ï¼ˆéœ€è¦çº¿ç¨‹å®‰å…¨ï¼Œå› ä¸ºå¯èƒ½åœ¨å¤šä¸ªçº¿ç¨‹ä¸­è°ƒç”¨ï¼‰
			let dataSize = UInt32(int16Data.count)
			// ä½¿ç”¨åŸå­æ“ä½œæˆ–é”æ¥æ›´æ–° wavDataSize
			// ç”±äº processAudioWriteQueue åœ¨ audioWriteQueue ä¸²è¡Œé˜Ÿåˆ—ä¸­æ‰§è¡Œï¼Œè¿™é‡Œä¸éœ€è¦é¢å¤–çš„é”
			wavDataSize += dataSize
			
			// æ›´æ–°æ€»å¸§æ•°ï¼ˆç”¨äºç»Ÿè®¡ï¼‰
			totalFramesWritten += Int64(frameCount)
			
			// è¯Šæ–­æ—¥å¿—ï¼šè®°å½•å†™å…¥æˆåŠŸï¼ˆå‰10æ¬¡å¼ºåˆ¶è®°å½•ï¼Œä¹‹åæ¯50æ¬¡è®°å½•ä¸€æ¬¡ï¼‰
			let shouldLogAppend = processedInThisCall <= 10 || processedInThisCall % 50 == 0 || processQueueCount <= 10
			if shouldLogAppend {
				print("[WebRTCConnector] âœ… [å†™å…¥æˆåŠŸ] [\(item.source)] æ ·æœ¬å·²å†™å…¥ - å¤„ç†#\(processQueueCount), æœ¬æ¬¡å¤„ç†#\(processedInThisCall), å¸§æ•°: \(frameCount), æ•°æ®å¤§å°: \(dataSize) å­—èŠ‚")
			}
		}
		
		// è¯Šæ–­æ—¥å¿—ï¼šè®°å½•æœ¬æ¬¡å¤„ç†å®Œæˆï¼ˆå‰10æ¬¡æˆ–æ¯5000æ¬¡è®°å½•ä¸€æ¬¡ï¼‰
		if processQueueCount <= 10 || processQueueCount % timestampCallFlag == 0 {
			bufferQueueLock.lock()
			let finalQueueSize = audioBufferQueue.count
			bufferQueueLock.unlock()
			print("[WebRTCConnector] ğŸ” [é˜Ÿåˆ—å¤„ç†] å®Œæˆå¤„ç† #\(processQueueCount) - æœ¬æ¬¡å¤„ç†: \(processedInThisCall) ä¸ªæ ·æœ¬, å‰©ä½™é˜Ÿåˆ—: \(finalQueueSize)")
		}
	}
}

extension WebRTCConnector: LKRTCPeerConnectionDelegate {
	public func peerConnectionShouldNegotiate(_: LKRTCPeerConnection) {}
    
    public func peerConnection(_ peerConnection: LKRTCPeerConnection, didAdd rtpReceiver: LKRTCRtpReceiver, streams mediaStreams: [LKRTCMediaStream]) {
		// è¯Šæ–­æ—¥å¿—ï¼šè®°å½•è¿œç¨‹éŸ³é¢‘è½¨é“è·å–å°è¯•
		print("[WebRTCConnector] ğŸ” [è¿œç¨‹éŸ³é¢‘è½¨é“] å¼€å§‹è·å–è¿œç¨‹éŸ³é¢‘è½¨é“")
		print("  - RTP Receiver track ç±»å‹: \(type(of: rtpReceiver.track))")
		print("  - åª’ä½“æµæ•°é‡: \(mediaStreams.count)")
		
		// æ–°ç‰ˆæœ¬ APIï¼šä» RTP Receiver ç›´æ¥è·å–éŸ³é¢‘è½¨é“ï¼ˆæ¨èæ–¹å¼ï¼‰
		if let audioTrack = rtpReceiver.track as? LKRTCAudioTrack {
			remoteAudioTrack = audioTrack
			print("[WebRTCConnector] âœ… [è¿œç¨‹éŸ³é¢‘è½¨é“] ä» RTP Receiver è·å–è¿œç¨‹éŸ³é¢‘è½¨é“æˆåŠŸ")
			print("  - è½¨é“ID: \(audioTrack.trackId)")
			print("  - æ˜¯å¦å¯ç”¨: \(audioTrack.isEnabled)")
			print("  - çŠ¶æ€: \(audioTrack.readyState.rawValue)")
			print("  - æ˜¯å¦æ­£åœ¨å½•åˆ¶: \(isRecording)")
			
			// å¦‚æœæ­£åœ¨å½•åˆ¶ï¼Œè¿æ¥è¿œç¨‹éŸ³é¢‘è½¨é“
			if isRecording {
				print("[WebRTCConnector] ğŸ” [è¿œç¨‹éŸ³é¢‘è½¨é“] æ­£åœ¨å½•åˆ¶ï¼Œå°è¯•è¿æ¥è¿œç¨‹éŸ³é¢‘è½¨é“")
				connectRemoteAudioToEngine()
			} else {
				print("[WebRTCConnector] ğŸ” [è¿œç¨‹éŸ³é¢‘è½¨é“] æœªåœ¨å½•åˆ¶ï¼Œæš‚ä¸è¿æ¥")
			}
			return
		}
		
		// è¯Šæ–­æ—¥å¿—ï¼šå¦‚æœæœªæ‰¾åˆ°è¿œç¨‹éŸ³é¢‘è½¨é“
		if remoteAudioTrack == nil {
			print("[WebRTCConnector] âš ï¸ [è¿œç¨‹éŸ³é¢‘è½¨é“] æœªæ‰¾åˆ°è¿œç¨‹éŸ³é¢‘è½¨é“")
		}
	}
	
	// ä¿ç•™æ—§ç‰ˆæœ¬ API ä½œä¸ºå…¼å®¹ï¼ˆå¦‚æœæ–°ç‰ˆæœ¬ API æœªè¢«è°ƒç”¨æ—¶ä½¿ç”¨ï¼‰
	public func peerConnection(_: LKRTCPeerConnection, didAdd stream: LKRTCMediaStream) {
		// æå–è¿œç¨‹éŸ³é¢‘è½¨é“ï¼ˆAIå›å¤ï¼‰
        print("[WebRTCConnector] ä»æ—§ç‰ˆæœ¬ API è·å–è¿œç¨‹éŸ³é¢‘è½¨é“")
//		let audioTracks = stream.audioTracks
//		if !audioTracks.isEmpty {
//			remoteAudioTrack = audioTracks.first
//			print("[WebRTCConnector] ä»æ—§ç‰ˆæœ¬ API è·å–è¿œç¨‹éŸ³é¢‘è½¨é“")
//			// å¦‚æœæ­£åœ¨å½•åˆ¶ï¼Œè¿æ¥è¿œç¨‹éŸ³é¢‘è½¨é“
//			if isRecording {
//				connectRemoteAudioToEngine()
//			}
//		}
	}
	
	public func peerConnection(_: LKRTCPeerConnection, didOpen _: LKRTCDataChannel) {}
	public func peerConnection(_: LKRTCPeerConnection, didRemove _: LKRTCMediaStream) {}
	public func peerConnection(_: LKRTCPeerConnection, didChange _: LKRTCSignalingState) {}
	public func peerConnection(_: LKRTCPeerConnection, didGenerate _: LKRTCIceCandidate) {}
	public func peerConnection(_: LKRTCPeerConnection, didRemove _: [LKRTCIceCandidate]) {}
	public func peerConnection(_: LKRTCPeerConnection, didChange _: LKRTCIceGatheringState) {}

	public func peerConnection(_: LKRTCPeerConnection, didChange newState: LKRTCIceConnectionState) {
		print("ICE Connection State changed to: \(newState)")
	}
}

extension WebRTCConnector: LKRTCDataChannelDelegate {
	public func dataChannel(_: LKRTCDataChannel, didReceiveMessageWith buffer: LKRTCDataBuffer) {
		do { try stream.yield(decoder.decode(ServerEvent.self, from: buffer.data)) }
		catch {
			print("Failed to decode server event: \(String(data: buffer.data, encoding: .utf8) ?? "<invalid utf8>")")
			stream.finish(throwing: error)
		}
	}

	public func dataChannelDidChangeState(_ dataChannel: LKRTCDataChannel) {
		Task { @MainActor [state = dataChannel.readyState] in
			switch state {
				case .open: 
					status = .connected
					// è¿æ¥æˆåŠŸåè‡ªåŠ¨å¼€å§‹å½•åˆ¶
					Task {
						try? await startRecording()
					}
				case .closing, .closed: 
					status = .disconnected
				default: break
			}
		}
	}
}



