import AVFAudio
import Foundation
@preconcurrency import LiveKitWebRTC

@MainActor
public final class WebRTCAudioRecorder: NSObject, LKRTCAudioRenderer {
    
    private var remoteAudioFile: AVAudioFile?
    private var localAudioFile: AVAudioFile?
    private var isRecording = false
    private var remoteAudioURL: URL?
    private var localAudioURL: URL?
    
    /// å¼€å§‹å½•åˆ¶
    public func startRecording() throws -> (remote: URL, local: URL) {
        let tempDir = FileManager.default.temporaryDirectory
        let remoteFileName = "remote_\(UUID().uuidString).wav"
        let localFileName = "local_\(UUID().uuidString).wav"
        
        remoteAudioURL = tempDir.appendingPathComponent(remoteFileName)
        localAudioURL = tempDir.appendingPathComponent(localFileName)
        
        // åˆ›å»ºéŸ³é¢‘æ–‡ä»¶ï¼ˆPCMæ ¼å¼ï¼Œä¾¿äºåç»­å¤„ç†ï¼‰
        let settings: [String: Any] = [
            AVFormatIDKey: Int(kAudioFormatLinearPCM),
            AVSampleRateKey: 24000.0,  // WebRTCé€šå¸¸ä½¿ç”¨24kHz
            AVNumberOfChannelsKey: 1,   // å•å£°é“
            AVLinearPCMBitDepthKey: 16,
            AVLinearPCMIsFloatKey: false,
            AVLinearPCMIsBigEndianKey: false
        ]
        
        remoteAudioFile = try AVAudioFile(forWriting: remoteAudioURL!, settings: settings)
        localAudioFile = try AVAudioFile(forWriting: localAudioURL!, settings: settings)
        
        isRecording = true
        print("ğŸ™ï¸ [WebRTCAudioRecorder] å¼€å§‹å½•åˆ¶éŸ³é¢‘åˆ°: \(remoteAudioURL!.lastPathComponent)")
        return (remoteAudioURL!, localAudioURL!)
    }
    
    /// LKRTCAudioRendereråè®®æ–¹æ³• - æ¥æ”¶è¿œç¨‹éŸ³é¢‘æ•°æ®
    public func renderPCMData(_ audioData: UnsafePointer<Int16>, 
                              samples: Int, 
                              sampleRate: Double, 
                              channels: Int) {
        guard isRecording, let file = remoteAudioFile else { return }
        
        // å°†PCMæ•°æ®å†™å…¥æ–‡ä»¶
        autoreleasepool {
            let format = AVAudioFormat(
                commonFormat: .pcmFormatInt16,
                sampleRate: sampleRate,
                channels: AVAudioChannelCount(channels),
                interleaved: true
            )!
            
            guard let buffer = AVAudioPCMBuffer(
                pcmFormat: format,
                frameCapacity: AVAudioFrameCount(samples)
            ) else { return }
            
            buffer.frameLength = AVAudioFrameCount(samples)
            
            // å¤åˆ¶éŸ³é¢‘æ•°æ®
            let channelData = buffer.int16ChannelData!
            for i in 0..<samples * channels {
                channelData.pointee[i] = audioData[i]
            }
            
            do {
                try file.write(from: buffer)
            } catch {
                print("âŒ [WebRTCAudioRecorder] å†™å…¥è¿œç¨‹éŸ³é¢‘å¤±è´¥: \(error)")
            }
        }
    }
    
    /// å†™å…¥æœ¬åœ°éŸ³é¢‘æ•°æ®ï¼ˆä»éº¦å…‹é£ï¼‰
    public func writeLocalAudio(_ buffer: AVAudioPCMBuffer) {
        guard isRecording, let file = localAudioFile else { return }
        
        do {
            try file.write(from: buffer)
        } catch {
            print("âŒ [WebRTCAudioRecorder] å†™å…¥æœ¬åœ°éŸ³é¢‘å¤±è´¥: \(error)")
        }
    }
    
    /// åœæ­¢å½•åˆ¶å¹¶åˆå¹¶éŸ³é¢‘
    public func stopRecording() -> URL? {
        isRecording = false
        
        remoteAudioFile = nil
        localAudioFile = nil
        
        // åˆå¹¶è¿œç¨‹å’Œæœ¬åœ°éŸ³é¢‘
        guard let remoteURL = remoteAudioURL,
              let localURL = localAudioURL else {
            print("âš ï¸ [WebRTCAudioRecorder] éŸ³é¢‘æ–‡ä»¶URLä¸ºç©º")
            return nil
        }
        
        let mergedURL = mergeAudioFiles(remote: remoteURL, local: localURL)
        print("ğŸ™ï¸ [WebRTCAudioRecorder] åœæ­¢å½•åˆ¶éŸ³é¢‘: \(mergedURL?.lastPathComponent ?? "nil")")
        return mergedURL
    }
    
    /// åˆå¹¶è¿œç¨‹å’Œæœ¬åœ°éŸ³é¢‘æ–‡ä»¶
    private func mergeAudioFiles(remote: URL, local: URL) -> URL? {
        let outputURL = FileManager.default.temporaryDirectory
            .appendingPathComponent("conversation_\(UUID().uuidString).m4a")
        
        do {
            // ä½¿ç”¨AVAssetExportSessionåˆå¹¶éŸ³é¢‘
            let remoteAsset = AVAsset(url: remote)
            let localAsset = AVAsset(url: local)
            
            let composition = AVMutableComposition()
            
            // æ·»åŠ è¿œç¨‹éŸ³é¢‘è½¨é“ï¼ˆAIè¯­éŸ³ï¼‰
            guard let remoteTrack = remoteAsset.tracks(withMediaType: .audio).first,
                  let compositionTrack = composition.addMutableTrack(withMediaType: .audio, preferredTrackID: kCMPersistentTrackID_Invalid) else {
                print("âŒ [WebRTCAudioRecorder] æ— æ³•æ·»åŠ è¿œç¨‹éŸ³é¢‘è½¨é“")
                return nil
            }
            
            try compositionTrack.insertTimeRange(
                CMTimeRange(start: .zero, duration: remoteAsset.duration),
                of: remoteTrack,
                at: .zero
            )
            
            // æ·»åŠ æœ¬åœ°éŸ³é¢‘è½¨é“ï¼ˆç”¨æˆ·è¯­éŸ³ï¼‰
            guard let localTrack = localAsset.tracks(withMediaType: .audio).first,
                  let localCompositionTrack = composition.addMutableTrack(withMediaType: .audio, preferredTrackID: kCMPersistentTrackID_Invalid) else {
                print("âŒ [WebRTCAudioRecorder] æ— æ³•æ·»åŠ æœ¬åœ°éŸ³é¢‘è½¨é“")
                return nil
            }
            
            try localCompositionTrack.insertTimeRange(
                CMTimeRange(start: .zero, duration: localAsset.duration),
                of: localTrack,
                at: .zero
            )
            
            // å¯¼å‡ºåˆå¹¶åçš„éŸ³é¢‘
            guard let exportSession = AVAssetExportSession(asset: composition, presetName: AVAssetExportPresetAppleM4A) else {
                print("âŒ [WebRTCAudioRecorder] æ— æ³•åˆ›å»ºå¯¼å‡ºä¼šè¯")
                return nil
            }
            
            exportSession.outputURL = outputURL
            exportSession.outputFileType = .m4a
            
            let semaphore = DispatchSemaphore(value: 0)
            var exportError: Error?
            
            exportSession.exportAsynchronously {
                if exportSession.status == .failed {
                    exportError = exportSession.error
                }
                semaphore.signal()
            }
            
            semaphore.wait()
            
            if let error = exportError {
                print("âŒ [WebRTCAudioRecorder] éŸ³é¢‘åˆå¹¶å¤±è´¥: \(error)")
                return nil
            }
            
            print("âœ… [WebRTCAudioRecorder] éŸ³é¢‘åˆå¹¶æˆåŠŸ: \(outputURL.lastPathComponent)")
            return outputURL
            
        } catch {
            print("âŒ [WebRTCAudioRecorder] éŸ³é¢‘åˆå¹¶å¼‚å¸¸: \(error)")
            return nil
        }
    }
    
    /// è·å–å½•åˆ¶çŠ¶æ€
    public var isCurrentlyRecording: Bool {
        return isRecording
    }
    
    /// è·å–è¿œç¨‹éŸ³é¢‘æ–‡ä»¶URL
    public func getRemoteAudioURL() -> URL? {
        return remoteAudioURL
    }
    
    /// è·å–æœ¬åœ°éŸ³é¢‘æ–‡ä»¶URL
    public func getLocalAudioURL() -> URL? {
        return localAudioURL
    }
}

public enum WebRTCAudioRecorderError: Error {
    case fileCreationFailed
    case audioMergeFailed
    case invalidAudioFormat
}
